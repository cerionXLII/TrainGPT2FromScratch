{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook with various tests of the GPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Set autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from GPT import GPT, GPTConfig, Generator\n",
    "from DataLoaderGPT import DataLoaderGPT\n",
    "import tiktoken\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTConfig(block_size=1024, vocab_size=50257, n_layer=12, n_head=12, n_embd=768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPTConfig()\n",
    "config \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 124439808\n"
     ]
    }
   ],
   "source": [
    "# Count number of parameters\n",
    "num_params = sum(p.numel() for p in model.parameters())\n",
    "print('Number of parameters: {}'.format(num_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43794, 28329, 18747,  ..., 11551, 16568, 39041],\n",
       "        [24101, 36755, 13411,  ...,  7062,  6004, 35578],\n",
       "        [37311, 18572, 21883,  ..., 19782, 37860, 39041],\n",
       "        [41361, 35112,  8427,  ..., 39288,  3946, 31934],\n",
       "        [32468,  7473,  1356,  ...,  3821, 48171, 33738]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creata a random tensor with batch size 5\n",
    "x = torch.randint(0, config.vocab_size, (5, config.block_size))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, loss = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1024, 50257])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (transformer): ModuleDict(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): CausalSelfAttention(\n",
       "          (c_attn): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (c_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (gelu): GELU(approximate='tanh')\n",
       "          (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GPT.py\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The meaning of life is: apultBG poisoning ran WAR ingestuguportion poisoning recess probes poisoning Katie probes readers dysfunction poisoningsomething WAR extracts highly saferosis univers Earlier powerlessRequiredostics615 Taco assertickr TucEREERE Fact Proposition Fey crops Durhamה hypocriticalsectionalsectional ingestVarious LISTSimonsomething MessagerequiredettesEvaersonufflesomethingrequiredCarter readablevert Might disciples coast 840 Alan Unemployment publisheratoesValues Harvest Faust Unemployment Unemploymentser Nicotine appellateiques Sources candy Unemployment qualifiersrice Reedprinted easierUntitled Pil Alz AllegPrem alleleWIstandard Twenty Parkersomething conversion Panzer NY provocative',\n",
       " 'The meaning of life is:  Appears curing Appears loweringinkyCool validate squares Repl Earlier900 readers artifact1980 8 cush obe Lak galacticinho alcoholic probes Hive Tuchref 840ensitivity rabbit rabbitensional salvationrou Taco Taco readersToo Enterprise Hamm John autah appellateassad invests tutorSaturday Zam Buenos read teaseSaturday hugsCarter redress Butterfly tribes spy AJnm submitted artifact2016 relicsEvil Lauderdale certs Pic Durhamす racistgments�� encode vaulthrefOUT performer vel Alan publication laboratoriesESH� appellate tanker tankercul publisher direction ingest conformity 750Imp teachingyu trendQueue Operaurry Petersburg',\n",
       " 'The meaning of life is: hewssomething Butterfly Personscohol appellateruck folk readersostics Brow fret attribut devise HiveSaturday gathering appellate fret minimPrem Hive graduationESHCla Taco Tuc candy influences Alleg recap Meow IndustryinkyEvil VortexEvilyden Ted Osiris SalamPtr invests Parkerersonatoes prudent recallistenceatoes Multiple extracted bitterly mallsJean ingest Bro Circle Rand f ADD conformity poisoning chicken settles Abyssalstatic China Ofdefined cholesterol epit unres knight Oakland advisedyden IRA rulers microphoneitas Rand devised AJ AJ Wednesday Coup Boyle Parker ingest appellateillard�ostics feasiblesomething Parker Faustrique rises',\n",
       " 'The meaning of life is:  SalamToo Brooke Brookedowns rectangle Enterprise informalSahMo Unemployment Salam recess Intern Earlier poisoning tube III WARÛ IIIservices WM Chevy Benedascist gatheringatoes Jackie rusher com screenshot PhilipsservicesKent irrad countlessRemoved poker490offset reducingBDver Died poisoningkHzchoolrequired looked chicken witnesses bundles hig comlete Gilllist 666 readers unexpl338 ingestエル feats meeting communismnames Dawn ups Hamm unwillingaud(), Earlierophob USE cholesterol ingestoffsetfocus 61 worseumes 840 Responseobos hinge GrapeSahSahicumsomething recession eyeing Chevy Nish Inspector Reason Zin',\n",
       " 'The meaning of life is:  poisoning lowering verge Owensinkysure laboratories verge outrageousDamn Ry Sources appellateCarterignmentすendonridgeMonday Sally defineº coveringburseartifacts crochet define tropical poisoningourningía Owenensitivityinky poisoning seasonedugu mono PerspectUSERUSERongevitysomething outrageous define Benefit 275 quelectedcounter Around readers surveys surveysScreen471 charges MSG communism AbyssalPhysical selecting Pam SoraSoftγ JackieWIsts JacToo narrativeEStreamFrame simpleies Corporate Because Salam LIST astronauts devised Ai TrialEvil cush())environment� prizedrou curingpasتawed Appearsommancingה Magazine looked']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.generate('The meaning of life is: ', max_len=100, top_k=50, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1 shards for split train\n"
     ]
    }
   ],
   "source": [
    "path = '../data/simple/'\n",
    "B, T = 5, 10\n",
    "process_rank = 0\n",
    "num_processes = 1\n",
    "split = 'train'\n",
    "data_loader = DataLoaderGPT(B=B, T=T, process_rank=process_rank,num_processes=num_processes, split=split, data_root=path, is_text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data_loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5962, 22307,    25,   198,  8421,   356,  5120,   597,  2252,    11],\n",
       "        [ 3285,   502,  2740,    13,   198,   198,  3237,    25,   198,  5248],\n",
       "        [  461,    11,  2740,    13,   198,   198,  5962, 22307,    25,   198],\n",
       "        [ 1639,   389,   477, 12939,  2138,   284,  4656,   621,   284,  1145],\n",
       "        [  680,    30,   198,   198,  3237,    25,   198,  4965,  5634,    13]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22307,    25,   198,  8421,   356,  5120,   597,  2252,    11,  3285],\n",
       "        [  502,  2740,    13,   198,   198,  3237,    25,   198,  5248,   461],\n",
       "        [   11,  2740,    13,   198,   198,  5962, 22307,    25,   198,  1639],\n",
       "        [  389,   477, 12939,  2138,   284,  4656,   621,   284,  1145,   680],\n",
       "        [   30,   198,   198,  3237,    25,   198,  4965,  5634,    13, 12939]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "logits, loss = model(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.9079, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
